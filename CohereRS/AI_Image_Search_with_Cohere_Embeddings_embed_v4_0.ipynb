{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD90Y2fOlD/60G2DG2lKCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashivashankars/CMPE256_Assignments/blob/main/AI_Image_Search_with_Cohere_Embeddings_embed_v4_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AI Image Search with Cohere Embeddings - embed-v4.0\n",
        "\n",
        "Learning objective: Embeddings are a way to represent the meaning of texts, images, or information as a list of numbers. Using a simple comparison function, we can then calculate a similarity score for two embeddings to figure out whether two pieces of information are about similar things. Common use-cases for embeddings include semantic search, clustering, and classification.\n",
        "\n",
        "In the following code, use the embed-v4.0 model to generate embeddings for attached images  and compare them using a similarity function."
      ],
      "metadata": {
        "id": "LGrWPfSnfEVm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "959abef6",
        "outputId": "dbfc9665-986e-49b7-85f6-4c093815a4c9"
      },
      "source": [
        "!pip install cohere"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cohere in /usr/local/lib/python3.12/dist-packages (5.19.0)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.12/dist-packages (from cohere) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.11.10)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.33.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from cohere) (0.22.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (2.32.4.20250913)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->cohere) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.5.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers<1,>=0.15->cohere) (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oSDPjKHqfBMk"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import numpy as np\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Setup ----------\n",
        "co = cohere.ClientV2(api_key=\"urtWH3GhzA2nRsS6UGquUxZlu43kwaXIcxJP8PSS\")\n",
        "def image_to_base64_data_url(image_path):\n",
        "#\"\"\"Convert image to base64 data URL\"\"\"\n",
        "  with Image.open(image_path) as img:\n",
        "    buffered = BytesIO()\n",
        "    img.save(buffered, format=\"PNG\")\n",
        "    img_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "  return f\"data:image/png;base64,{img_base64}\"\n",
        "def image_to_base64_data_url_old(image_path: str) -> str:\n",
        "  with Image.open(image_path) as img:\n",
        "    buf = BytesIO()\n",
        "    img.save(buf, format=\"PNG\")\n",
        "    b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "  return f\"data:image/png;base64,{b64}\"\n",
        "def l2_normalize(v: np.ndarray) -> np.ndarray:\n",
        "  n = np.linalg.norm(v, axis=-1, keepdims=True) + 1e-12\n",
        "  return v / n\n",
        "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
        "# assumes both are already L2-normalized\n",
        "  return float(np.dot(a, b))\n"
      ],
      "metadata": {
        "id": "N1qRTsV5fRXi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Build image embedding store ----------\n",
        "def embed_images(image_paths: List[str]) -> List[Tuple[str, np.ndarray]]:\n",
        "  data_urls = [image_to_base64_data_url(p) for p in image_paths]\n",
        "  res = co.embed(\n",
        "  images=data_urls,\n",
        "  model=\"embed-v4.0\",\n",
        "  embedding_types=[\"float\"],\n",
        "  input_type=\"image\",)\n",
        "  vecs = [np.array(v, dtype=np.float32) for v in res.embeddings.float]\n",
        "  vecs = l2_normalize(np.stack(vecs, axis=0))\n",
        "  return list(zip(image_paths, vecs))"
      ],
      "metadata": {
        "id": "h697Qgs0fU-4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Natural-language search over images ----------\n",
        "def search_images(\n",
        "query: str,\n",
        "image_index: List[Tuple[str, np.ndarray]],\n",
        "top_k: int = 5\n",
        ") -> List[Tuple[str, float]]:\n",
        "  qres = co.embed(\n",
        "  texts=[query],\n",
        "  model=\"embed-v4.0\",\n",
        "  embedding_types=[\"float\"],\n",
        "  input_type=\"search_query\", # key for cross-modal retrieval\n",
        ")\n",
        "  print(\"qres\")\n",
        "  embedding_vector = qres.embeddings.float[0]\n",
        "  print(\"qres Embedding vector length:\", len(embedding_vector))\n",
        "  qvec = np.array(qres.embeddings.float[0], dtype=np.float32)\n",
        "  qvec = l2_normalize(qvec)\n",
        "\n",
        "  # --- Retrieve embedding and token count ---\n",
        "  #embedding_vector = qres.embeddings.float[0]\n",
        "  scored = []\n",
        "  for path, ivec in image_index:\n",
        "    score = cosine_sim(qvec, ivec)\n",
        "    scored.append((path, score))\n",
        "  scored.sort(key=lambda x: x[1], reverse=True)\n",
        "  return scored[:top_k]"
      ],
      "metadata": {
        "id": "APctpjFffcv6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Embed a small corpus of images\n",
        "image_paths = [\n",
        "\"person_with_cap.jpg\" , \"cart_with_single_tire.jpg\",\n",
        "]\n",
        "image_index = embed_images(image_paths)\n",
        "print(image_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE1_M4vpfnLa",
        "outputId": "753bceef-1178-453a-c07d-499b4a34d28d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('person_with_cap.jpg', array([-0.02044545,  0.03461122,  0.04877699, ...,  0.03096024,\n",
            "       -0.03037609, -0.02526473], dtype=float32)), ('cart_with_single_tire.jpg', array([-0.00240004,  0.02031567,  0.03473581, ...,  0.01975798,\n",
            "       -0.01027734, -0.00213115], dtype=float32))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Run a natural-language query\n",
        "#query = \"person handling a package on a residential porch; delivery truck on the street\"\n",
        "#query = \"Wells Fargo check\"\n",
        "#query = \"glasses, necklace, hill with sun and fence\"\n",
        "#query = \"Can we copy Strike ?\"\n",
        "query = \"person with tape and cap\"\n",
        "#query = \"cart with single tire\"\n",
        "#query = \"glasses, sun, hills, red shirt\"\n",
        "results = search_images(query, image_index, top_k=3)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4kM3he7fqZW",
        "outputId": "175f03a6-f67e-48eb-959c-c1c68b3efc8d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qres\n",
            "qres Embedding vector length: 1536\n",
            "[('person_with_cap.jpg', 0.1719561219215393), ('cart_with_single_tire.jpg', 0.043788447976112366)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Show results\n",
        "print(\"\\nTop matches:\")\n",
        "for path, score in results:\n",
        "  print(f\"{path} | cosine={score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTSzEW6jftUe",
        "outputId": "caffddcb-3163-4346-dc5d-e8477e31ddfa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top matches:\n",
            "person_with_cap.jpg | cosine=0.1720\n",
            "cart_with_single_tire.jpg | cosine=0.0438\n"
          ]
        }
      ]
    }
  ]
}